% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/experiments.R
\name{train_and_evaluate.tf_experiment}
\alias{train_and_evaluate.tf_experiment}
\title{Interleaves Training and Evaluation}
\usage{
train_and_evaluate.tf_experiment(object, ...)
}
\arguments{
\item{object}{A TensorFlow experiment.}

\item{...}{Optional arguments, passed to the experiment's \code{train_and_evaluate()}
method.}
}
\value{
The result of the \code{evaluate} call to the \code{Estimator} as well as the
export results using the specified \code{ExportStrategy}.
}
\description{
The frequency of evaluation is controlled by the contructor arg
\code{min_eval_frequency}. When this parameter is 0, evaluation happens only after
training has completed. Note that evaluation cannot happen more frequently
than checkpoints are taken. If no new snapshots are available when evaluation
is supposed to occur, then evaluation doesn't happen for another
\code{min_eval_frequency} steps (assuming a checkpoint is available at that
point). Thus, settings \code{min_eval_frequency} to 1 means that the model will be
evaluated everytime there is a new checkpoint. This is particular useful for
a "Master" task in the cloud, whose responsibility it is to take checkpoints,
evaluate those checkpoints, and write out summaries. Participating in
training as the supervisor allows such a task to accomplish the first and
last items, while performing evaluation allows for the second. Returns: The
result of the \code{evaluate} call to the \code{Estimator} as well as the export
results using the specified \code{ExportStrategy}.
}
\seealso{
Other experiment methods: \code{\link{evaluate.tf_experiment}},
  \code{\link{experiment.tf_estimator}},
  \code{\link{train.tf_experiment}}
}
