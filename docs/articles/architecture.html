<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Package Architecture and Components • tfestimators</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">tfestimators</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/architecture.html">Architecture</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/tfestimators">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Package Architecture and Components</h1>
            
          </div>

    
    
<div class="contents">
<div id="estimator" class="section level2">
<h2 class="hasAnchor">
<a href="#estimator" class="anchor"></a>Estimator</h2>
<p>Estimator is a class that provides an abstraction for a machine learning model. It is designed to be detailed enough to allow for downstream infrastructure to be written, but general enough to not constrain the type of model represented by an Estimator. The general interface for users of Estimator is loosely modeled after Scikit-learn and consists of only three methods: <code>fit()</code> trains the model, given training data; <code>evaluate()</code> computes evaluation metrics over test data; and <code>predict()</code> performs inference on new data given a trained model. (TODO: More description)</p>
<div id="canned-estimators" class="section level3">
<h3 class="hasAnchor">
<a href="#canned-estimators" class="anchor"></a>Canned Estimators</h3>
<p>This library provides canned Estimators that have already implemented the model layers and architecture, such as Estimators for linear models, Deep Neural Networks, Support Vector Machines, state saving Recurrent Neural Networks, dynamic Recurrent Neural Networks, etc. Users only need to focus on defining the input and features used to train a model, evaluate it, and predict with it. Users then should be able to choose freely the level of abstraction best suited for the problem at hand.</p>
<p>In order to use canned Estimators, users need to specify the input function, feature columns, and other required parameters that are specific to the choice of canned Estimator.</p>
<p>Users firstly specify the feature columns that represent the feature transformations to be used by the Estimator. Here we use the default function <code>feature_columns()</code> to automatically map each features in a dataset into a feature column according to their types, e.g. factor variable, numeric variable, etc.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mtcars$vs &lt;-<span class="st"> </span><span class="kw">as.factor</span>(mtcars$vs)
dnn_feature_columns &lt;-<span class="st"> </span><span class="kw">feature_columns</span>(mtcars, <span class="st">"drat"</span>)
linear_feature_columns &lt;-<span class="st"> </span><span class="kw">feature_columns</span>(mtcars, <span class="st">"cyl"</span>)</code></pre></div>
<p>Then use <code>input_fn</code> to specify the response variable as well as the predictor variables in the dataset, which converts the variables in the in-memory data set into Tensors that can be consumed by Estimator:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">custom_input_fn &lt;-<span class="st"> </span><span class="kw"><a href="../reference/input_fn.html">input_fn</a></span>(mtcars, <span class="dt">response =</span> <span class="st">"vs"</span>, <span class="dt">features =</span> <span class="kw">c</span>(<span class="st">"drat"</span>, <span class="st">"cyl"</span>))</code></pre></div>
<p>Next, we intialize the Linear DNN Combined canned Estimator by passing the feature columns and other parameters that specifies the layers and architecture of the model. Note that for this particular canned Estimator, it takes two types of feature columns that are used for constructing linear layer and fully connected deep layers separately:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
classifier &lt;-
<span class="st">    </span><span class="kw"><a href="../reference/linear_dnn_combined_classifier.html">linear_dnn_combined_classifier</a></span>(
      <span class="dt">linear_feature_columns =</span> linear_feature_columns,
      <span class="dt">dnn_feature_columns =</span> dnn_feature_columns,
      <span class="dt">dnn_hidden_units =</span> <span class="kw">c</span>(3L, 3L),
      <span class="dt">dnn_optimizer =</span> <span class="st">"Adagrad"</span>
    )</code></pre></div>
<p>Users can then call <code>train()</code> to train the initialized Estimator for a number of steps:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">classifier &lt;-<span class="st"> </span><span class="kw">train</span>(classifier, <span class="dt">input_fn =</span> custom_input_fn, <span class="dt">steps =</span> 2L)</code></pre></div>
<p>Once a model is trained, users can use <code>predict()</code> that makes predictions on a given input function that represents the inference data source. an argument named <code>type</code> can be <code>"raw"</code> so <code>predict()</code> will return the raw predictions outcomes, as well as <code>"prob"</code> and <code>"logistic"</code> that returns prediction probabilities and logistics if a model is of classification type.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(classifier, <span class="dt">input_fn =</span> custom_input_fn)
predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(classifier, <span class="dt">input_fn =</span> custom_input_fn, <span class="dt">type =</span> <span class="st">"prob"</span>)
predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(classifier, <span class="dt">input_fn =</span> custom_input_fn, <span class="dt">type =</span> <span class="st">"logistic"</span>)</code></pre></div>
<p>There’s also a function called <code>coef()</code> that can be used extract the trained coefficients of a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(classifier)</code></pre></div>
</div>
<div id="custom-estimator" class="section level3">
<h3 class="hasAnchor">
<a href="#custom-estimator" class="anchor"></a>Custom Estimator</h3>
<p>Users can also implement their own custom Estimator by configuring the layers and architecture of the Estimator. The Estimator’s architecture is configured using a user-defined <code>model_fn</code>, a function which builds a TensorFlow graph and returns necessary information to train a model, evaluate it, and predict with it. Users writing custom estimators to implement custom model architecture only have to implement this function to specify the layers of the custom Estimator. It is possible, and in fact, common, that <code>model_fn</code> contains regular TensorFlow without using any other part of our framework. It is often the case because existing models are being adapted or converted to be implemented in terms of an estimator.</p>
<p>Users define the model architecture in a custom model function <code>custom_model_fn</code> that contains the following arguments in the signature that users can grab to define customized handling conditionally:</p>
<ul>
<li>features and labels of the model.</li>
<li>mode that contains the different modes of a model, such as training, inference, or evaluation.</li>
<li>params that contains the tuning parameters in a model.</li>
<li>config that represents the <code>RunConfig</code> objects used in a model, including GPU percentages, cluster information, etc.</li>
</ul>
<p>The <code>custom_model_fn()</code> function should return an <code><a href="../reference/estimator_spec.html">estimator_spec(predictions, loss, train_op, mode)</a></code> that contains the predictions, losses, training op, and mode.</p>
<p>The following example demonstrates the construction and fitting of a custom estimator that has custom architectures.</p>
<p>Firstly, let’s define the input using <code><a href="../reference/input_fn.html">input_fn()</a></code>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">constructed_input_fn &lt;-<span class="st"> </span><span class="kw"><a href="../reference/input_fn.html">input_fn</a></span>(
    <span class="dt">object =</span> iris,
    <span class="dt">response =</span> <span class="st">"Species"</span>,
    <span class="dt">features =</span> <span class="kw">c</span>(
      <span class="st">"Sepal.Length"</span>,
      <span class="st">"Sepal.Width"</span>,
      <span class="st">"Petal.Length"</span>,
      <span class="st">"Petal.Width"</span>),
    <span class="dt">batch_size =</span> 10L
)</code></pre></div>
<p>Next, we define the custom model function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
custom_model_fn &lt;-<span class="st"> </span>function(features, labels, mode, params, config) {
      <span class="co"># Create three fully connected layers respectively of size 10, 20, and 10 with</span>
    <span class="co"># each layer having a dropout probability of 0.1.</span>
    logits &lt;-<span class="st"> </span>features %&gt;%
<span class="st">      </span>tf$contrib$layers$<span class="kw">stack</span>(
        tf$contrib$layers$fully_connected, <span class="kw">c</span>(10L, 20L, 10L),
        <span class="dt">normalizer_fn =</span> tf$contrib$layers$dropout,
        <span class="dt">normalizer_params =</span> <span class="kw">list</span>(<span class="dt">keep_prob =</span> <span class="fl">0.9</span>)) %&gt;%
<span class="st">      </span>tf$contrib$layers$<span class="kw">fully_connected</span>(3L, <span class="dt">activation_fn =</span> <span class="ot">NULL</span>) <span class="co"># Compute logits (1 per class) and compute loss.</span>
    
    predictions &lt;-<span class="st"> </span><span class="kw">list</span>(
      <span class="dt">class =</span> tf$<span class="kw">argmax</span>(logits, 1L),
      <span class="dt">prob =</span> tf$nn$<span class="kw">softmax</span>(logits))
    
    <span class="co"># Return estimator_spec early with NULL loss and train_op during inference mode</span>
    if(mode ==<span class="st"> "infer"</span>){
      <span class="kw">return</span>(<span class="kw"><a href="../reference/estimator_spec.html">estimator_spec</a></span>(
      <span class="dt">predictions =</span> predictions, <span class="dt">mode =</span> mode, <span class="dt">loss =</span> <span class="ot">NULL</span>, <span class="dt">train_op =</span> <span class="ot">NULL</span>))
    }
    
    labels &lt;-<span class="st"> </span>tf$<span class="kw">one_hot</span>(labels, 3L)
    loss &lt;-<span class="st"> </span>tf$losses$<span class="kw">softmax_cross_entropy</span>(labels, logits)
    
    <span class="co"># Create a tensor for training op.</span>
    train_op &lt;-<span class="st"> </span>tf$contrib$layers$<span class="kw">optimize_loss</span>(
      loss,
      tf$contrib$framework$<span class="kw">get_global_step</span>(),
      <span class="dt">optimizer =</span> <span class="st">'Adagrad'</span>,
      <span class="dt">learning_rate =</span> <span class="fl">0.1</span>)
    
    <span class="kw">return</span>(<span class="kw"><a href="../reference/estimator_spec.html">estimator_spec</a></span>(predictions, loss, train_op, mode))
}

<span class="co"># Initialize and fit the model using the the custom model function we defined</span>
<span class="co"># and the constructed_input_fn that represents the input data source.  </span>
classifier &lt;-<span class="st"> </span><span class="kw"><a href="../reference/estimator.html">estimator</a></span>(<span class="dt">model_fn =</span> custom_model_fn)
classifier &lt;-<span class="st"> </span><span class="kw">train</span>(classifier, <span class="dt">input_fn =</span> constructed_input_fn, <span class="dt">steps =</span> 2L)</code></pre></div>
<p>Note that the above code contains a lot of <code>$</code>s. It is unnecessary to create wrapper APIs for every methods that users might use, e.g. <code>tf$contrib$layers$optimize_loss</code>, since custom models are designed to be flexible and extensible so users can insert any arbitrary low level TensorFlow APIs.</p>
<p>Users can then supply new data in <code>input_fn</code> to <code>predict()</code> and make predictions using the trained model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predictions &lt;-<span class="st"> </span><span class="kw">predict</span>(classifier, <span class="dt">input_fn =</span> constructed_input_fn)</code></pre></div>
<p>Since our predictions is defined as a list of two named items in the custom model function like follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predictions &lt;-<span class="st"> </span><span class="kw">list</span>(
  <span class="dt">class =</span> tf$<span class="kw">argmax</span>(logits, 1L),
  <span class="dt">prob =</span> tf$nn$<span class="kw">softmax</span>(logits))</code></pre></div>
<p>we can then loop through each prediction and collect the predicted classes and probabilities like the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># extract predicted classes</span>
predicted_classes &lt;-<span class="st"> </span><span class="kw">lapply</span>(predictions, function(prediction) prediction$class)

<span class="co"># extract the raw probabilities for each new row of data and for each class</span>
predicted_raw_probs &lt;-<span class="st"> </span><span class="kw">lapply</span>(predictions, function(prediction) prediction$prob)</code></pre></div>
<p>Users can also pass <code>model_dir</code> which is the directory to save model parameters, graph and etc. This can also be used to load checkpoints from the directory into a estimator to continue training a previously saved model. Users can also pass a <code>config</code> to canned Estimator or custom Estimator that specify the model run-time configuration, such as cluster information, GPU fractions, etc.</p>
</div>
</div>
<div id="feature-columns" class="section level2">
<h2 class="hasAnchor">
<a href="#feature-columns" class="anchor"></a>Feature Columns</h2>
<p>Feature columns are used to specify the feature transformations and combinations for a model, e.g. <code><a href="../reference/column_embedding.html">column_embedding()</a></code> that converts a categorical variable into embedding and <code><a href="../reference/column_crossed.html">column_crossed()</a></code> that combines two variables in a specified way.</p>
<p>Users can use the default <code>feature_columns()</code> function to convert columns in an automatic fashion without any fancy feature engineering, e.g. numeric variables are converted using <code><a href="../reference/column_real_valued.html">column_real_valued()</a></code>, factor variables are converted using <code>column_with_keys()</code>, and character variables are converted using <code>column_with_hash_bucket()</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fcs &lt;-<span class="st"> </span><span class="kw">feature_columns</span>(mtcars, <span class="kw">c</span>(<span class="st">"drat"</span>, <span class="st">"cyl"</span>))</code></pre></div>
<p>Users can also write their own custom feature columns transformation function like the following that transforms different columns in a <code>lapply</code> loop.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">custom_feature_columns &lt;-<span class="st"> </span>function(x, columns) {
  <span class="kw">ensure_valid_column_names</span>(x, columns)
  function() {
    <span class="kw">lapply</span>(columns, function(column_name) {
      column_values &lt;-<span class="st"> </span>x[[column_name]]
      if (column_name ==<span class="st"> "profit"</span>) {
        <span class="kw"><a href="../reference/column_real_valued.html">column_real_valued</a></span>(column_name)
      } else if (column_name ==<span class="st"> "profession"</span>) {
        <span class="kw">column_with_keys</span>(column_name)
      } else {
        ...
      }
    })
  }
}</code></pre></div>
<p>The feature columns transformation functions are wrappers around Python <code>tf.contrib.layers.feature_column</code> module, for example, <code><a href="../reference/column_real_valued.html">column_real_valued()</a></code> is essentially <code>tf.contrib.layers.feature_column.real_valued_column</code>, we wrap it this way so users can just type <code>column_</code> and utilize the autocomplete functionality in RStudio to find available types of feature columns faster as well as reducing the appearances of <code>$</code> in the code. A variety of feature column functions are available. For example, <code><a href="../reference/column_one_hot.html">column_one_hot()</a></code> specifies a feature column that’s one-hot encoded, <code><a href="../reference/column_sparse_weighted.html">column_sparse_weighted()</a></code> creates a feature column in combination with a designated weight column.</p>
</div>
<div id="input-function" class="section level2">
<h2 class="hasAnchor">
<a href="#input-function" class="anchor"></a>Input Function</h2>
<p>Input function is where users provide the input sources to feed into the model, e.g. in-memory dataframe/matrix, streaming data, serialized data formats, etc.</p>
<p>Users have two ways to specify in-memory data set - using formula interface or passing <code>features</code> and <code>response</code> arguments. For example, users can use built-in <code><a href="../reference/input_fn.html">input_fn()</a></code> on <code>data.frame/matrix</code> objects like the following:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/input_fn.html">input_fn</a></span>(mtcars, <span class="dt">response =</span> <span class="st">"mpg"</span>, <span class="dt">features =</span> <span class="kw">c</span>(<span class="st">"drat"</span>, <span class="st">"cyl"</span>))</code></pre></div>
<p>or use the formulate interface like below where left-hand and right-hand side of the <code>~</code> represent response column and feature columns respectively:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/input_fn.html">input_fn</a></span>(mpg ~<span class="st"> </span>drat +<span class="st"> </span>cyl, <span class="dt">data =</span> mtcars)</code></pre></div>
<p>There’s also a built-in <code><a href="../reference/input_fn.html">input_fn()</a></code> that works on nested lists, for example:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/input_fn.html">input_fn</a></span>(
  <span class="dt">object =</span> <span class="kw">list</span>(
    <span class="dt">features =</span> <span class="kw">list</span>(
      <span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">1</span>), <span class="kw">list</span>(<span class="dv">2</span>), <span class="kw">list</span>(<span class="dv">3</span>)),
      <span class="kw">list</span>(<span class="kw">list</span>(<span class="dv">4</span>), <span class="kw">list</span>(<span class="dv">5</span>), <span class="kw">list</span>(<span class="dv">6</span>))),
    <span class="dt">response =</span> <span class="kw">list</span>(
      <span class="kw">list</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="kw">list</span>(<span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>))),
  <span class="dt">features =</span> <span class="st">"features"</span>,
  <span class="dt">response =</span> <span class="st">"response"</span>)</code></pre></div>
<p>In the above example, the data is a list of two named lists where each named list can be seen as different columns in a dataset. In this case, a column named <code>features</code> is being used as features to the model and a column named <code>response</code> is being used as the response variable. This nested lists format is particularly useful when constructing sequence input to Recurrent Neural Networks (RNN). Once the data is defined using <code><a href="../reference/input_fn.html">input_fn()</a></code>, it can be used directly in RNN constructor.</p>
<p>Users can also write custom input function, e.g. a function <code>custom_input_fn()</code>, to convert each feature into a <code>Tensor</code> or <code>SparseTensor</code> according to the needs. The following skeleton code has a few places commented with “custom code here” that users can use to do customized operation. Other parts should remain unchanged.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">custom_input_fn &lt;-<span class="st">  </span>function(
  x,
  features,
  <span class="dt">response =</span> <span class="ot">NULL</span>)
{
  <span class="kw">validate_input_fn_args</span>(x, features, response)
  function(is_canned_estimator) {
    function() {
      if (is_canned_estimator) {
        <span class="co"># Change this block if this input_fn is used in canned estimators</span>
        input_features &lt;-<span class="st"> </span><span class="kw">lapply</span>(features, function(feature) {
          <span class="kw">custom_function</span>(x[[feature]], ...) <span class="co"># custom code here</span>
        })
        <span class="kw">names</span>(input_features) &lt;-<span class="st"> </span>features
      } else {
        <span class="co"># Change this block if this input_fn is used in custom estimators</span>
        input_features &lt;-<span class="st"> </span><span class="kw">custom_function</span>(<span class="kw">as.matrix</span>(x[, features]), ...) <span class="co"># custom code here</span>
      }
      if (!<span class="kw">is.null</span>(response)) {
        input_response &lt;-<span class="st"> </span><span class="kw">custom_function</span>(x[[response]], ...) <span class="co"># custom code here</span>
      } else {
        input_response &lt;-<span class="st"> </span><span class="ot">NULL</span>
      }
      <span class="kw">list</span>(input_features, input_response)
    }
  }
}</code></pre></div>
<p>Users are encounraged to follow the above skeleton but it may not be suitable for all types of models. For example, if a user want to construct some complicated input, such as a batched sequence input similar to a sine curve for feeding RNNs, he can define something similar to the following using mostly low-level TensorFlow APIs:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">get_batched_sin_input_fn &lt;-<span class="st"> </span>function(batch_size, sequence_length, increment, <span class="dt">seed =</span> <span class="ot">NULL</span>) {
    function(unused_arg) {
      function() {
        starts &lt;-<span class="st"> </span>random_ops$<span class="kw">random_uniform</span>(
          <span class="kw">list</span>(batch_size), <span class="dt">minval =</span> <span class="dv">0</span>, <span class="dt">maxval =</span> pi *<span class="st"> </span><span class="fl">2.0</span>,
          <span class="dt">dtype =</span> tf$python$framework$dtypes$float32, <span class="dt">seed =</span> seed)
        sin_curves &lt;-<span class="st"> </span>functional_ops$<span class="kw">map_fn</span>(
          function(x){
            math_ops$<span class="kw">sin</span>(
              math_ops$<span class="kw">linspace</span>(
                array_ops$<span class="kw">reshape</span>(x[<span class="dv">1</span>], <span class="kw">list</span>()),
                (sequence_length -<span class="st"> </span><span class="dv">1</span>) *<span class="st"> </span>increment,
                <span class="kw">as.integer</span>(sequence_length +<span class="st"> </span><span class="dv">1</span>)))
          },
          <span class="kw">tuple</span>(starts),
          <span class="dt">dtype =</span> tf$python$framework$dtypes$float32
        )
        inputs &lt;-<span class="st"> </span>array_ops$<span class="kw">expand_dims</span>(
          array_ops$<span class="kw">slice</span>(
            sin_curves,
            np$<span class="kw">array</span>(<span class="kw">list</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">dtype =</span> np$int64),
            np$<span class="kw">array</span>(<span class="kw">list</span>(batch_size, sequence_length), <span class="dt">dtype =</span> np$int64)),
          2L
        )
        labels &lt;-<span class="st"> </span>array_ops$<span class="kw">slice</span>(sin_curves,
                                  np$<span class="kw">array</span>(<span class="kw">list</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">dtype =</span> np$int64),
                                  np$<span class="kw">array</span>(<span class="kw">list</span>(batch_size, sequence_length), <span class="dt">dtype =</span> np$int64))
        <span class="kw">tuple</span>(<span class="kw">list</span>(<span class="dt">inputs =</span> inputs), labels)
      }
  }
}</code></pre></div>
<p>Users can then further define <code>input_fn</code> for training and evaluation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_input_fn &lt;-<span class="st"> </span><span class="kw">get_batched_sin_input_fn</span>(batch_size, sequence_length, pi /<span class="st"> </span><span class="dv">32</span>, <span class="dt">seed =</span> <span class="dv">1234</span>)
eval_input_fn &lt;-<span class="st"> </span><span class="kw">get_batched_sin_input_fn</span>(batch_size, sequence_length, pi /<span class="st"> </span><span class="dv">32</span>, <span class="dt">seed =</span> <span class="dv">4321</span>)</code></pre></div>
</div>
<div id="experiments" class="section level2">
<h2 class="hasAnchor">
<a href="#experiments" class="anchor"></a>Experiments</h2>
<p>Experiments are designed for easier experiments, e.g. define your model, specify training and evaluation data and steps, frequencies, where to run, metrics to use to monitor the process, etc. They contain all neccessary information required, such as <code>input_fn</code> for both training and evaluation, to run experiments and can be easily packed up to run in cloud, local, or cluster environment.</p>
<p>For example, we firstly construct a classifier</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">clf &lt;-
<span class="st">  </span><span class="kw"><a href="../reference/linear_dnn_combined_classifier.html">linear_dnn_combined_classifier</a></span>(
    <span class="dt">linear_feature_columns =</span> linear_feature_columns,
    <span class="dt">dnn_feature_columns =</span> dnn_feature_columns,
    <span class="dt">dnn_hidden_units =</span> <span class="kw">c</span>(3L, 3L),
    <span class="dt">dnn_optimizer =</span> <span class="st">"Adagrad"</span>
  )
  </code></pre></div>
<p>and then we pass the classifier into <code>experiment()</code> together with other neccessary information, such as separate input functions for training and evaluation, training and avaluation steps, etc. Then we can call <code>train_and_evaluate()</code> to conduct the experiment by running training and evaluation altogether.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
experiment &lt;-<span class="st"> </span><span class="kw">experiment</span>(
  clf,
  <span class="dt">train_input_fn =</span> custom_train_input_fn,
  <span class="dt">eval_input_fn =</span> custom_eval_input_fn,
  <span class="dt">train_steps =</span> 3L,
  <span class="dt">eval_steps =</span> 3L,
  <span class="dt">continuous_eval_throttle_secs =</span> 60L
)

experiment_result &lt;-<span class="st"> </span><span class="kw">train_and_evaluate</span>(experiment)</code></pre></div>
</div>
<div id="sessionrunhooks" class="section level2">
<h2 class="hasAnchor">
<a href="#sessionrunhooks" class="anchor"></a>SessionRunHooks</h2>
<p><code>SessionRunHooks</code> are useful to track training, report progress, request early stopping and more. Users can attach an arbitrary number of hooks to an estimator. <code>SessionRunHooks</code> use the observer pattern and notify at the following points:</p>
<ul>
<li>when a session starts being used</li>
<li>before a call to the <code>session.run()</code>
</li>
<li>after a call to the <code>session.run()</code>
</li>
<li>when the session closed</li>
</ul>
<p>A <code>SessionRunHook</code> encapsulates a piece of reusable/composable computation that can piggyback a call to <code>MonitoredSession.run()</code>. A hook can add any ops-or-tensor/feeds to the run call, and when the run call finishes with success gets the outputs it requested. Hooks are allowed to add ops to the graph in <code>hook.begin()</code>. The graph is finalized after the <code>begin()</code> method is called.</p>
<p>There are a few pre-defined <code>SessionRunHooks</code> available, for example: - <code>hook_stop_at_step</code>: Request stop based on global_step. - <code>hook_checkpoint_saver</code>: Saves checkpoint. - <code>hook_logging_tensor</code>: Outputs one or more tensor values to log. - <code>hook_nan_tensor</code>: Request stop if given <code>Tensor</code> contains Nans. - <code>hook_summary_saver</code>: Saves summaries to a summary writer. - <code>hook_global_step_waiter</code>: Delays execution until reaching a certain global step.</p>
<p>Similarly to feature columns, all available <code>SessionRunHooks</code> are named with <code>hook_xxx</code> to utilize the autocomplete functionality to speed up searching for available types of <code>SessionRunHooks</code>.</p>
<p>For example, in order to customize the checkpoint saving mechanism, users can initialize a monitor using <code><a href="../reference/hook_checkpoint_saver.html">hook_checkpoint_saver()</a></code> that defines the checkpoint directory and the frequency of saving new checkpoint.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">monitor &lt;-<span class="st"> </span><span class="kw"><a href="../reference/hook_checkpoint_saver.html">hook_checkpoint_saver</a></span>(
  <span class="dt">checkpoint_dir =</span> <span class="st">"/tmp/ckpt_dir"</span>,
  <span class="dt">save_secs =</span> <span class="dv">2</span>)</code></pre></div>
<p>Once monitor and an estimator are defined, the monitor can be attached to the estimator via the argument <code>monitors</code> when fitting the model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lr &lt;-<span class="st"> </span><span class="kw"><a href="../reference/linear_dnn_combined_regressor.html">linear_dnn_combined_regressor</a></span>(
  <span class="dt">linear_feature_columns =</span> linear_feature_columns,
  <span class="dt">dnn_feature_columns =</span> dnn_feature_columns,
  <span class="dt">dnn_hidden_units =</span> <span class="kw">c</span>(1L, 1L),
  <span class="dt">dnn_optimizer =</span> <span class="st">"Adagrad"</span>
)

lr %&gt;%<span class="st"> </span><span class="kw">train</span>(
  <span class="dt">input_fn =</span> custom_input_fn,
  <span class="dt">steps =</span> 10L,
  <span class="dt">monitors =</span> monitor)</code></pre></div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#estimator">Estimator</a></li>
      <li><a href="#feature-columns">Feature Columns</a></li>
      <li><a href="#input-function">Input Function</a></li>
      <li><a href="#experiments">Experiments</a></li>
      <li><a href="#sessionrunhooks">SessionRunHooks</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Yuan Tang, JJ Allaire, <a href="https://www.rstudio.com"><img src="http://tidyverse.org/rstudio-logo.svg" height="24"></a>, Kevin Ushey.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
